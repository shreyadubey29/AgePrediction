{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 1\n",
    "CSCI-4930/5930 ML Spring 2019\n",
    "Author: Shreya Dubey "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "y = loadmat('wiki_labeled_1.mat')\n",
    "A = y['wiki_labeled']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data from the loaded mat file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = A['full_path'][0][0]\n",
    "AGE = A['age'][0][0]\n",
    "face_score = A['face_score'][0][0]\n",
    "second_face_score = A['second_face_score'][0][0]\n",
    "number = full_path.size\n",
    "final_full_path = full_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60327, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGE_new = np.transpose(AGE)\n",
    "AGE_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60327"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Images from the full_path from the .mat  file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d17b4b2533d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[1;31m#checking for outliers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond_face_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "X = np.empty((number, 100*100))\n",
    "\n",
    "n = 0\n",
    "n1 = 0 \n",
    "for i in final_full_path: \n",
    "    im_path = i[0]\n",
    "    path = 'wiki_labeled/wiki_labeled/' + str(im_path)\n",
    "  #checking for outliers  \n",
    "    if(math.isnan(second_face_score[:,n1][0] ) and (math.isfinite(face_score[:,n1][0]))):\n",
    "        im = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        X[n,:] = ( im.reshape(1,10000)  )\n",
    "        n = n + 1 \n",
    "        n1 = n1+1\n",
    "    else:\n",
    "        n1 = n1+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking only the images that are valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of images = ',n)\n",
    "X = X[0:n,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating mean to centralise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = (np.sum(X, axis = 0))/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (n):\n",
    "    X[i,:] = X[i,:]-X_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking out the outliers from the age data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_new_mod = np.empty((n, 1))\n",
    "num = 0\n",
    "num1 = 0 \n",
    "for i in range (number): \n",
    "    if(math.isnan(second_face_score[:,num1][0] ) and (math.isfinite(face_score[:,num1][0]))):\n",
    "        AGE_new_mod[num,:]  = AGE_new[i,:]     \n",
    "        num = num + 1 \n",
    "        num1 = num1+1\n",
    "    else:\n",
    "        num1 = num1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_new_mod.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into 80% training and 20% test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = np.append(X,AGE_new_mod,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X_total, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train[:,-1]\n",
    "y_test = X_test[:,-1]\n",
    "y_train.shape\n",
    "y_test.shape\n",
    "X_train = X_train[:,0:10000]\n",
    "X_test = X_test[:,0:10000]\n",
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_T = np.transpose(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_train = X_train_T@X_train\n",
    "C_train = C_train/(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the eigen values and eigen vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "\n",
    "w,v = LA.eig(C_train)\n",
    "print('v =',v)\n",
    "print('w =',w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the top 20 eigen faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,5, figsize=(10, 10))\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(20):\n",
    "    img1 = v[:,i]\n",
    "    img1 = img1.reshape(100,100)\n",
    "    axs[i].imshow(img1,cmap='gray')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the scree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.linspace(1,10000,10000)\n",
    "plt.figure(figsize = (12,10))\n",
    "plt.plot(K,w)\n",
    "plt.xlim(-10,70)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Eigen Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating plot between number of K values and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Si = sum(w)\n",
    "print('Total variance = ',Si)\n",
    "Sk = sum(w[0:15])\n",
    "print('% variance = ',(Sk/Si)*100)\n",
    "\n",
    "SumK = np.empty((1,10000))\n",
    "\n",
    "for i in range (10000):\n",
    "    SumK[:,i] = (sum(w[0:i])/Si)*100\n",
    "    \n",
    "    \n",
    "plt.figure(figsize = (12,10))\n",
    "plt.plot(K,SumK[0])\n",
    "plt.xlim(0,6000)\n",
    "plt.ylim(70,100)\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('% Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Value of K (depending on the scree plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_value = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projecting training data images on to the eigenfaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = v[:,0:K_value]\n",
    "\n",
    "X_data_pca = X_train@X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projecting test data images on to the eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = X_test@X_new\n",
    "\n",
    "#deleting X to release memory\n",
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "SC = MinMaxScaler()\n",
    "\n",
    "X_data_pca = SC.fit_transform(X_data_pca)\n",
    "\n",
    "X_test_pca = SC.transform(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts pandas Dataframe to numpy.ndarray\n",
    "ones = np.ones([X_data_pca.shape[0],1])\n",
    "X_data_pca = np.concatenate((ones,X_data_pca),axis=1)\n",
    "\n",
    "y = y_train\n",
    "\n",
    "#select initial weights. Taking all zeros to start with\n",
    "weight = np.zeros([1,X_data_pca.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set learning rate and number of iterations\n",
    "alpha = 0.00000001\n",
    "iters = 12000\n",
    "\n",
    "y_train.shape = (31122,1)\n",
    "\n",
    "# Print shapes of X, y and theta to make sure their dimensions are correct \n",
    "print(X_data_pca.shape) ; \n",
    "print(y_train.shape) ;\n",
    "print(weight.shape);\n",
    "\n",
    "#computeLost\n",
    "def computeLoss(X,y,weight):\n",
    "    \n",
    "    h = X@weight.T    # '@' for matrix multiplication. Alternatively matmult() can be used\n",
    "    error = h-y    \n",
    "    loss = np.power(error,2)\n",
    "    J = np.sum(loss)/(2*len(X))\n",
    "    return J\n",
    "\n",
    "print(computeLoss(X_data_pca,y_train,weight))\n",
    "\n",
    "m = X_data_pca.shape[0]\n",
    "\n",
    "#gradient descent\n",
    "def gradientDescent(X,y,weight,iters,alpha):\n",
    "    loss = np.zeros(iters)\n",
    "    for i in range(iters):\n",
    "        for j in range(m):\n",
    "            X_i = X[j,:]\n",
    "            X_i.shape = (1,K_value+1)\n",
    "            y_i = y[j,:]\n",
    "            y_i.shape = (1,1)\n",
    "            y_hat = X_i@weight.T\n",
    "            gradient = X_i.T@(y_hat - y_i)   \n",
    "            weight = weight - (alpha*gradient).T \n",
    "        loss[i] = computeLoss(X, y, weight) \n",
    "        \n",
    "        # print cost after every 100 iterations to keep a track of when the cost function converges\n",
    "        if i%100 == 0:\n",
    "            print(\"Iteration %d | loss: %f\" % (i, loss[i]))\n",
    "            \n",
    "    return weight,loss\n",
    "\n",
    "#running the gd and cost function\n",
    "W,loss = gradientDescent(X_data_pca,y_train,weight,iters,alpha)\n",
    "print(\"Weigths for the linear model\", W)\n",
    "\n",
    "finalCost = computeLoss(X_data_pca,y_train,W)\n",
    "print(finalCost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the RMSE on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the first column all ones\n",
    "ones = np.ones([X_test_pca.shape[0],1])\n",
    "X_test_pca = np.concatenate((ones,X_test_pca),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of X_test_pca: \", X_test_pca.shape)\n",
    "print(\"shape of W: \", W.shape)\n",
    "print(\"shape of y_test: \", y_test.shape)\n",
    "\n",
    "y_test.shape = (7781,1)\n",
    "y_learn = X_test_pca@W.T\n",
    "error = y_test - y_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRMSE(y_test,x_test,W):\n",
    "    err = y_test - (x_test@W.T)  \n",
    "    sq_err = err*err ; \n",
    "    mean_sqr_err = np.sum(sq_err, axis = 0 )/len(err)\n",
    "    RMSE = math.sqrt(mean_sqr_err)\n",
    "    return RMSE\n",
    "\n",
    "rmse1 = getRMSE(y_test,X_test_pca,W)\n",
    "print(\"Root Mean Squared Error = \", rmse1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#RMSE1 = 18.062686675869838\n",
    "#RMSE2 = 16.73084347718248\n",
    "#RMSE3 = 16.617141336336186\n",
    "#RMSE4 = 16.807692550390442\n",
    "#RMSE5 = 18.352997171428015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R =[18.062686675869838,16.73084347718248,16.617141336336186,16.807692550390442,18.352997171428015]\n",
    "Avg_rmse = np.mean(R)\n",
    "stdv_rmse = np.std(R)\n",
    "\n",
    "print('Average RMSE = ',Avg_rmse)\n",
    "print('Standard deviation of RMSE =',stdv_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_v = [2,10,20,40,50,60,80,100,200]\n",
    "RMSE_v = [17.076894074696263,16.686346916598435,17.24229549812708,17.1501307646619,17.087651807277023,17.076223134162554,17.154376556864765,17.119457525152008,17.17250913355512]\n",
    "\n",
    "plt.plot(K_v,RMSE_v,'b-')\n",
    "plt.ylim(10,20)\n",
    "plt.ylabel('RMSE values')\n",
    "plt.xlabel('value of K')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the wiki_judge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_judge = loadmat('wiki_judgeX.mat')\n",
    "A_judge = y_judge['wiki_judgeX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_full_path = A_judge['full_path'][0][0]\n",
    "image_number = image_full_path.size\n",
    "final_full_path_judge = image_full_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_judge = np.empty((image_number, 100*100))\n",
    "\n",
    "n = 0 \n",
    "for i in final_full_path_judge: \n",
    "    im_path = i[0]\n",
    "    path = 'wiki_judge_images/wiki_judge_images/' + str(im_path)\n",
    "    im = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    X_judge[n,:] = ( im.reshape(1,10000)  )\n",
    "    n = n + 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (n):\n",
    "    X_judge[i,:] = X_judge[i,:]-X_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_judge.shape\n",
    "X_judge_pca = X_judge@X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_judge_pca = SC.transform(X_judge_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the age values for wiki_judge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones([X_judge_pca.shape[0],1])\n",
    "X_judge_pca = np.concatenate((ones,X_judge_pca),axis=1)\n",
    "Age_output = X_judge_pca@W.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'age':Age_output[:,0]})\n",
    "\n",
    "dataset.to_csv('AGE_PREDICTION.csv', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
